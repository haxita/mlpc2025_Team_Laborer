{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342fc1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files: 8230\n",
      " Train: 5761, Val: 1234, Test: 1235\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "label_dir    = '/home/mtang/vslib/mlpc2025_Team_Laborer/MLPC2025_classification/labels'\n",
    "out_dir      = '/home/mtang/vslib/mlpc2025_Team_Laborer/notebooks/Task3/tang'\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "all_npz   = [f for f in os.listdir(label_dir) if f.endswith('_labels.npz')]\n",
    "all_files = sorted([f.replace('_labels.npz', '.mp3') for f in all_npz])\n",
    "\n",
    "rng       = np.random.RandomState(47)\n",
    "shuffled  = rng.permutation(all_files)\n",
    "n         = len(shuffled)\n",
    "n_train   = int(0.70 * n)\n",
    "n_val     = int(0.15 * n)\n",
    "train_files = list(shuffled[:n_train])\n",
    "val_files   = list(shuffled[n_train:n_train + n_val])\n",
    "test_files  = list(shuffled[n_train + n_val:])\n",
    "\n",
    "print(f\"Total files: {n}\")\n",
    "print(f\" Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}\")\n",
    "\n",
    "split_df = pd.DataFrame({\n",
    "    'filename': train_files + val_files + test_files,\n",
    "    'split':    ['train'] * len(train_files) +\n",
    "                ['val'] * len(val_files) +\n",
    "                ['test'] * len(test_files)\n",
    "})\n",
    "out_path = os.path.join(out_dir, 'data_split_tang.csv')\n",
    "split_df.to_csv(out_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b4ffe3",
   "metadata": {},
   "source": [
    "split the data as file not as frame to avoid data leakage.\n",
    "\n",
    "70%train,15%validation,15%test\n",
    "\n",
    "with same random seed (47) to assure consistency\n",
    "\n",
    "unbiaseed performance is achived by not involve test dataset in any step before the model is done training.\n",
    "\n",
    "use validaton data set for perameter adjustment. and test run the training code.\n",
    "\n",
    "use training data set for model training. when the best perameter is set in place, and the final model is done training. we can try the model on the test data set and then report the result.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpc2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
